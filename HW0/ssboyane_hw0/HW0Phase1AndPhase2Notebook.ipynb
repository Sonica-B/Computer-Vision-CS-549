{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sonica-B/Computer-Vision-CS-549/blob/HW0/HW0/ssboyane_hw0/HW0Phase1AndPhase2Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoAmRych4zjz"
      },
      "source": [
        "# RBE/CS549 Fall 2022: Computer Vision\n",
        "## Homework 0: Alohomora\n",
        "\n",
        "Author(s):\n",
        "Prof. Nitin J. Sanket (nsanket@wpi.edu), Lening Li (lli4@wpi.edu), Gejji, Vaishnavi Vivek (vgejji@wpi.edu)\n",
        "\n",
        "Robotics Engineering Department,\n",
        "\n",
        "Worcester Polytechnic Institute\n",
        "\n",
        "Code adapted from CMSC733 at the University of Maryland, College Park."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Phase 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_OTbKmZc84z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the BSDS500 dataset"
      ],
      "metadata": {
        "id": "tShNtcK9syo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/leelening/rbe549/main/hw0/BSDS500.tar.xz\n",
        "!tar -xvf BSDS500.tar.xz\n",
        "!mv BSDS500/ /content/data/"
      ],
      "metadata": {
        "id": "6poCzkgco7sv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b237e1e8-57db-431a-c973-4a8e7f1a5529"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-10 22:31:17--  https://raw.githubusercontent.com/leelening/rbe549/main/hw0/BSDS500.tar.xz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 812060 (793K) [application/octet-stream]\n",
            "Saving to: ‘BSDS500.tar.xz’\n",
            "\n",
            "BSDS500.tar.xz      100%[===================>] 793.03K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-01-10 22:31:18 (20.7 MB/s) - ‘BSDS500.tar.xz’ saved [812060/812060]\n",
            "\n",
            "BSDS500/\n",
            "BSDS500/CannyBaseline/\n",
            "BSDS500/CannyBaseline/1.png\n",
            "BSDS500/CannyBaseline/10.png\n",
            "BSDS500/CannyBaseline/2.png\n",
            "BSDS500/CannyBaseline/3.png\n",
            "BSDS500/CannyBaseline/4.png\n",
            "BSDS500/CannyBaseline/5.png\n",
            "BSDS500/CannyBaseline/6.png\n",
            "BSDS500/CannyBaseline/7.png\n",
            "BSDS500/CannyBaseline/8.png\n",
            "BSDS500/CannyBaseline/9.png\n",
            "BSDS500/GroundTruth/\n",
            "BSDS500/GroundTruth/1.png\n",
            "BSDS500/GroundTruth/10.png\n",
            "BSDS500/GroundTruth/2.png\n",
            "BSDS500/GroundTruth/3.png\n",
            "BSDS500/GroundTruth/4.png\n",
            "BSDS500/GroundTruth/5.png\n",
            "BSDS500/GroundTruth/6.png\n",
            "BSDS500/GroundTruth/7.png\n",
            "BSDS500/GroundTruth/8.png\n",
            "BSDS500/GroundTruth/9.png\n",
            "BSDS500/Images/\n",
            "BSDS500/Images/1.jpg\n",
            "BSDS500/Images/10.jpg\n",
            "BSDS500/Images/2.jpg\n",
            "BSDS500/Images/3.jpg\n",
            "BSDS500/Images/4.jpg\n",
            "BSDS500/Images/5.jpg\n",
            "BSDS500/Images/6.jpg\n",
            "BSDS500/Images/7.jpg\n",
            "BSDS500/Images/8.jpg\n",
            "BSDS500/Images/9.jpg\n",
            "BSDS500/SobelBaseline/\n",
            "BSDS500/SobelBaseline/1.png\n",
            "BSDS500/SobelBaseline/10.png\n",
            "BSDS500/SobelBaseline/2.png\n",
            "BSDS500/SobelBaseline/3.png\n",
            "BSDS500/SobelBaseline/4.png\n",
            "BSDS500/SobelBaseline/5.png\n",
            "BSDS500/SobelBaseline/6.png\n",
            "BSDS500/SobelBaseline/7.png\n",
            "BSDS500/SobelBaseline/8.png\n",
            "BSDS500/SobelBaseline/9.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/leelening/rbe549/main/hw0/TxtFiles.tar.xz\n",
        "!tar -xvf TxtFiles.tar.xz\n",
        "!mv TxtFiles/ /content/data/"
      ],
      "metadata": {
        "id": "6FH307bN0MDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b88cc4-5f16-403b-9446-86274d233ae9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-10 22:31:21--  https://raw.githubusercontent.com/leelening/rbe549/main/hw0/TxtFiles.tar.xz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 55376 (54K) [application/octet-stream]\n",
            "Saving to: ‘TxtFiles.tar.xz’\n",
            "\n",
            "TxtFiles.tar.xz     100%[===================>]  54.08K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2025-01-10 22:31:21 (6.17 MB/s) - ‘TxtFiles.tar.xz’ saved [55376/55376]\n",
            "\n",
            "TxtFiles/\n",
            "TxtFiles/DirNamesTest.txt\n",
            "TxtFiles/DirNamesTrain.txt\n",
            "TxtFiles/LabelsTest.txt\n",
            "TxtFiles/LabelsTrain.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lak3Alk44zj1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FilterUtils:\n",
        "    \"\"\"Base utilities for all filter types\"\"\"\n",
        "\n",
        "\n",
        "    def create_gaussian_kernel(size, sigma_x, sigma_y=None):\n",
        "        \"\"\"\n",
        "        Creates a 2D Gaussian kernel with optional different sigmas for x and y\n",
        "\n",
        "        Args:\n",
        "            size: Kernel size (must be odd)\n",
        "            sigma_x: Standard deviation in x direction\n",
        "            sigma_y: Standard deviation in y direction (if None, uses sigma_x)\n",
        "\n",
        "        Returns:\n",
        "            2D Gaussian kernel normalized to sum to 1\n",
        "        \"\"\"\n",
        "        size = int(size)\n",
        "        if size % 2 == 0:\n",
        "            size += 1  # Ensure odd size\n",
        "\n",
        "        if sigma_y is None:\n",
        "            sigma_y = sigma_x\n",
        "\n",
        "        # Create coordinate grid\n",
        "        halfsize = size // 2\n",
        "        x = np.linspace(-halfsize, halfsize, size)\n",
        "        y = np.linspace(-halfsize, halfsize, size)\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "\n",
        "        # Calculate Gaussian values\n",
        "        gaussian = np.exp(-(X**2 / (2*sigma_x**2) + Y**2 / (2*sigma_y**2)))\n",
        "\n",
        "        # Normalize\n",
        "        return gaussian / gaussian.sum()\n",
        "\n",
        "\n",
        "    def rotate_kernel(kernel, angle_degrees):\n",
        "        \"\"\"\n",
        "        Rotates a kernel by the specified angle using cv2\n",
        "\n",
        "        Args:\n",
        "            kernel: Input kernel to rotate\n",
        "            angle_degrees: Rotation angle in degrees\n",
        "\n",
        "        Returns:\n",
        "            Rotated kernel\n",
        "        \"\"\"\n",
        "        rows, cols = kernel.shape\n",
        "        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle_degrees, 1)\n",
        "        rotated = cv2.warpAffine(kernel, M, (cols, rows))\n",
        "        return rotated\n",
        "\n",
        "\n",
        "    def normalize_kernel(kernel):\n",
        "        \"\"\"\n",
        "        Normalizes a kernel to ensure it sums to 0 (for derivative filters)\n",
        "        or 1 (for smoothing filters)\n",
        "\n",
        "        Args:\n",
        "            kernel: Input kernel\n",
        "\n",
        "        Returns:\n",
        "            Normalized kernel\n",
        "        \"\"\"\n",
        "        if np.abs(kernel.sum()) < 1e-10:  # Derivative filter\n",
        "            return kernel / np.abs(kernel).sum()\n",
        "        else:  # Smoothing filter\n",
        "            return kernel / kernel.sum()"
      ],
      "metadata": {
        "id": "qVeJeFLnbivo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN-AX2a04zj2"
      },
      "source": [
        "1. Generate Difference of Gaussian Filter Bank: (DoG)\n",
        "2. Display all the filters in this filter bank and save image as DoG.png,\n",
        "3. use command \"cv2.imwrite(...)\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####  TEST2\n",
        "#from filter_utils import FilterUtils\n",
        "\n",
        "class DoGFilter:\n",
        "    \"\"\"Derivative of Gaussian Filter Implementation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.utils = FilterUtils()\n",
        "\n",
        "    def generate_filters(self, scales=2, orientations=16):\n",
        "        \"\"\"\n",
        "        Generates Derivative of Gaussian filters at multiple scales and orientations\n",
        "\n",
        "        Args:\n",
        "            scales: Number of scales\n",
        "            orientations: Number of orientations\n",
        "\n",
        "        Returns:\n",
        "            List of DoG filters\n",
        "        \"\"\"\n",
        "        filters = []\n",
        "\n",
        "        # Base Sobel kernel for x-direction\n",
        "        sobel_x = np.array([[-1, 0, 1],\n",
        "                           [-2, 0, 2],\n",
        "                           [-1, 0, 1]])\n",
        "\n",
        "        for scale in range(scales):\n",
        "            # Calculate sigma and kernel size for this scale\n",
        "            sigma = 2 ** scale\n",
        "            size = int(6 * sigma)  # 6 sigma rule for kernel size\n",
        "\n",
        "            # Generate Gaussian kernel\n",
        "            gaussian = self.utils.create_gaussian_kernel(size, sigma)\n",
        "\n",
        "            # Generate oriented filters for this scale\n",
        "            for theta in np.linspace(0, 180, orientations, endpoint=False):\n",
        "                # Rotate Sobel kernel\n",
        "                rotated_sobel = self.utils.rotate_kernel(sobel_x, theta)\n",
        "\n",
        "                # Convolve Gaussian with rotated Sobel\n",
        "                dog = cv2.filter2D(gaussian, -1, rotated_sobel)\n",
        "                dog = self.utils.normalize_kernel(dog)\n",
        "\n",
        "                filters.append(dog)\n",
        "\n",
        "        return filters"
      ],
      "metadata": {
        "id": "AcIJTctk8Mlk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UEpnMgO64zj3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "53ded4e0-bf88-4d6a-9cbc-40894e04ca54"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e4a8f481b62b>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Generate filter bank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mdog_filter_bank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dog_filter_bank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscales\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Display the filter bank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-e4a8f481b62b>\u001b[0m in \u001b[0;36mgenerate_dog_filter_bank\u001b[0;34m(scales, orientations)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_dog_filter_bank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscales\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0msobel_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msobel_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msobel_filters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscales\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-e4a8f481b62b>\u001b[0m in \u001b[0;36msobel_filters\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Function to create Sobel operators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msobel_filters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     sobel_x = np.array([[-1, 0, 1],\n\u001b[0m\u001b[1;32m     11\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                         [-1, 0, 1]])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "####  TEST1\n",
        "\n",
        "# Function to create Gaussian kernel\n",
        "def gaussian_kernel(size, sigma):\n",
        "    ax = np.linspace(-(size // 2), size // 2, size)\n",
        "    x, y = np.meshgrid(ax, ax)\n",
        "    kernel = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
        "    return kernel / kernel.sum()\n",
        "\n",
        "# Function to create Sobel operators\n",
        "def sobel_filters():\n",
        "    sobel_x = np.array([[-1, 0, 1],\n",
        "                        [-2, 0, 2],\n",
        "                        [-1, 0, 1]])\n",
        "    sobel_y = np.array([[1, 2, 1],\n",
        "                        [0, 0, 0],\n",
        "                        [-1, -2, -1]])\n",
        "    return sobel_x, sobel_y\n",
        "\n",
        "# Function to rotate a filter by a given angle\n",
        "def rotate_filter(filter, angle):\n",
        "    size = filter.shape[0]\n",
        "    center = size // 2\n",
        "    rotation_matrix = cv2.getRotationMatrix2D((center, center), angle, 1)\n",
        "    rotated_filter = cv2.warpAffine(filter, rotation_matrix, (size, size))\n",
        "    return rotated_filter\n",
        "\n",
        "# Function to generate the DoG filter bank\n",
        "def generate_dog_filter_bank(scales, orientations):\n",
        "    filters = []\n",
        "    sobel_x, sobel_y = sobel_filters()\n",
        "\n",
        "    for scale in scales:\n",
        "        # Generate Gaussian kernel\n",
        "        size = int(scale * 6)  # Kernel size proportional to scale\n",
        "        if size % 2 == 0:  # Ensure odd size\n",
        "            size += 1\n",
        "        gaussian = gaussian_kernel(size, scale)\n",
        "\n",
        "        # Compute Derivatives of Gaussian (DoG)\n",
        "        dog_x = np.convolve(gaussian.flatten(), sobel_x.flatten(), mode='same').reshape(size, size)\n",
        "        dog_y = np.convolve(gaussian.flatten(), sobel_y.flatten(), mode='same').reshape(size, size)\n",
        "\n",
        "        # Rotate DoG filters to generate orientations\n",
        "        for orientation in range(orientations):\n",
        "            angle = (360 / orientations) * orientation\n",
        "            rotated_x = rotate_filter(dog_x, angle)\n",
        "            rotated_y = rotate_filter(dog_y, angle)\n",
        "            filters.append(rotated_x + rotated_y)  # Combine x and y derivatives\n",
        "\n",
        "    return filters\n",
        "\n",
        "# Parameters\n",
        "scales = [2, 4]  # Two scales\n",
        "orientations = 16  # 16 orientations\n",
        "\n",
        "# Generate filter bank\n",
        "dog_filter_bank = generate_dog_filter_bank(scales, orientations)\n",
        "\n",
        "# Display the filter bank\n",
        "rows = len(scales)\n",
        "cols = orientations\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(15, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(dog_filter_bank[i], cmap='gray')\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the filter bank as an image\n",
        "dog_image = np.zeros((rows * 31, cols * 31))  # Assuming filter size is 31x31\n",
        "for i in range(rows):\n",
        "    for j in range(cols):\n",
        "        filter_resized = cv2.resize(dog_filter_bank[i * cols + j], (31, 31))\n",
        "        dog_image[i * 31:(i + 1) * 31, j * 31:(j + 1) * 31] = filter_resized\n",
        "\n",
        "cv2.imwrite(\"DoG_Filter_Bank.png\", (dog_image * 255).astype(np.uint8))\n",
        "print(\"DoG filter bank saved as 'DoG_Filter_Bank.png'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9sMEggi4zj3"
      },
      "source": [
        "\n",
        "1. Generate Leung-Malik Filter Bank: (LM)\n",
        "2. Display all the filters in this filter bank and save image as LM.png,\n",
        "3. use command \"cv2.imwrite(...)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### TEST2\n",
        "\n",
        "class LMFilter:\n",
        "    \"\"\"Leung-Malik Filter Implementation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.utils = FilterUtils()\n",
        "\n",
        "    def generate_filters(self, small_scale=True):\n",
        "        \"\"\"\n",
        "        Generates Leung-Malik filter bank\n",
        "\n",
        "        Args:\n",
        "            small_scale: If True, generates LMS, else LML\n",
        "\n",
        "        Returns:\n",
        "            List of LM filters\n",
        "        \"\"\"\n",
        "        filters = []\n",
        "\n",
        "        # Define scales based on filter type\n",
        "        if small_scale:\n",
        "            scales = [1, np.sqrt(2), 2, 2*np.sqrt(2)]  # LMS\n",
        "        else:\n",
        "            scales = [np.sqrt(2), 2, 2*np.sqrt(2), 4]  # LML\n",
        "\n",
        "        # Generate first and second derivative filters\n",
        "        orientations = 6\n",
        "        elongation = 3  # Elongation factor\n",
        "\n",
        "        for scale in scales[:3]:  # First 3 scales for derivatives\n",
        "            sigma = scale\n",
        "            size = int(6 * sigma * elongation)\n",
        "\n",
        "            for theta in np.linspace(0, 180, orientations, endpoint=False):\n",
        "                # First derivative\n",
        "                kernel_1st = self._create_derivative_kernel(size, sigma,\n",
        "                                                          elongation, theta, order=1)\n",
        "                filters.append(kernel_1st)\n",
        "\n",
        "                # Second derivative\n",
        "                kernel_2nd = self._create_derivative_kernel(size, sigma,\n",
        "                                                          elongation, theta, order=2)\n",
        "                filters.append(kernel_2nd)\n",
        "\n",
        "        # Generate Gaussian and LoG filters\n",
        "        for scale in scales:\n",
        "            size = int(6 * scale)\n",
        "\n",
        "            # Gaussian\n",
        "            gaussian = self.utils.create_gaussian_kernel(size, scale)\n",
        "            filters.append(gaussian)\n",
        "\n",
        "            # Laplacian of Gaussian\n",
        "            log = self._create_log_kernel(size, scale)\n",
        "            filters.append(log)\n",
        "\n",
        "        return filters\n",
        "\n",
        "    def _create_derivative_kernel(self, size, sigma, elongation, theta, order):\n",
        "        \"\"\"Helper method to create derivative kernels\"\"\"\n",
        "        sigma_y = sigma * elongation\n",
        "        kernel = self.utils.create_gaussian_kernel(size, sigma, sigma_y)\n",
        "\n",
        "        # Create coordinate grid\n",
        "        x = np.linspace(-size//2, size//2, size)\n",
        "        y = np.linspace(-size//2, size//2, size)\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "\n",
        "        # Rotate coordinates\n",
        "        theta_rad = np.deg2rad(theta)\n",
        "        Xr = X*np.cos(theta_rad) + Y*np.sin(theta_rad)\n",
        "\n",
        "        # Apply derivative\n",
        "        if order == 1:\n",
        "            kernel = kernel * (-Xr/(sigma**2))\n",
        "        else:  # order == 2\n",
        "            kernel = kernel * ((Xr**2/sigma**4) - 1/sigma**2)\n",
        "\n",
        "        return self.utils.normalize_kernel(kernel)\n",
        "\n",
        "    def _create_log_kernel(self, size, sigma):\n",
        "        \"\"\"Helper method to create LoG kernel\"\"\"\n",
        "        x = np.linspace(-size//2, size//2, size)\n",
        "        y = np.linspace(-size//2, size//2, size)\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "        R2 = X**2 + Y**2\n",
        "\n",
        "        # LoG equation\n",
        "        gaussian = self.utils.create_gaussian_kernel(size, sigma)\n",
        "        log = -1/(np.pi*sigma**4) * (1 - R2/(2*sigma**2)) * gaussian\n",
        "\n",
        "        return self.utils.normalize_kernel(log)"
      ],
      "metadata": {
        "id": "NXwfUctB85Is"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K_ihdTUc4zj3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b60a7cbd-500d-49de-fdd0-ef8dde48e86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leung-Malik filter bank saved as 'LM.png'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1200 with 40 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "### TEST1\n",
        "\n",
        "# Function to create Laplacian of Gaussian (LoG) kernel\n",
        "def laplacian_of_gaussian(size, sigma):\n",
        "    ax = np.linspace(-(size // 2), size // 2, size)\n",
        "    x, y = np.meshgrid(ax, ax)\n",
        "    log = -1 / (np.pi * sigma**4) * (1 - (x**2 + y**2) / (2 * sigma**2)) * np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
        "    return log\n",
        "\n",
        "# Function to generate LM filter bank\n",
        "def generate_lm_filter_bank(scales, orientations):\n",
        "    filters = []\n",
        "\n",
        "    for sigma in scales:\n",
        "        size = int(sigma * 6)\n",
        "        if size % 2 == 0:\n",
        "            size += 1\n",
        "\n",
        "        # Laplacian of Gaussian (LoG)\n",
        "        log = laplacian_of_gaussian(size, sigma)\n",
        "        filters.append(log)\n",
        "\n",
        "        # Gaussian\n",
        "        g = gaussian_kernel(size, sigma)\n",
        "        filters.append(g)\n",
        "\n",
        "    # Add DoG filters\n",
        "    dog_filters = generate_dog_filter_bank(scales, orientations)\n",
        "    filters.extend(dog_filters)\n",
        "\n",
        "    return filters\n",
        "\n",
        "# Parameters for LM filter bank\n",
        "lm_scales = [1, np.sqrt(2), 2, 2 * np.sqrt(2)]  # σ = {1, sqrt(2), 2, 2sqrt(2)}\n",
        "orientations = 6  # 6 orientations\n",
        "\n",
        "# Generate LM filter bank\n",
        "lm_filter_bank = generate_lm_filter_bank(lm_scales, orientations)\n",
        "\n",
        "# Display and save LM filter bank\n",
        "rows = len(lm_scales) + 1  # Additional row for DoG filters\n",
        "cols = orientations + 2  # LoG + Gaussian + orientations\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(15, 12))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < len(lm_filter_bank):\n",
        "        ax.imshow(lm_filter_bank[i], cmap='gray')\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the filter bank as an image\n",
        "lm_image = np.zeros((rows * 31, cols * 31))  # Assuming filter size is 31x31\n",
        "for i in range(rows):\n",
        "    for j in range(cols):\n",
        "        idx = i * cols + j\n",
        "        if idx < len(lm_filter_bank):\n",
        "            filter_resized = cv2.resize(lm_filter_bank[idx], (31, 31))\n",
        "            lm_image[i * 31:(i + 1) * 31, j * 31:(j + 1) * 31] = filter_resized\n",
        "\n",
        "cv2.imwrite(\"LM.png\", (lm_image * 255).astype(np.uint8))\n",
        "print(\"Leung-Malik filter bank saved as 'LM.png'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWPCb37t4zj3"
      },
      "source": [
        "1. Generate Gabor Filter Bank: (Gabor)\n",
        "2. Display all the filters in this filter bank and save image as Gabor.png,\n",
        "3. use command \"cv2.imwrite(...)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3RUEhBJ4zj4"
      },
      "outputs": [],
      "source": [
        "### TEST2\n",
        "\n",
        "class GaborFilter:\n",
        "    \"\"\"Gabor Filter Implementation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.utils = FilterUtils()\n",
        "\n",
        "    def generate_filters(self, scales=4, orientations=8):\n",
        "        \"\"\"\n",
        "        Generates Gabor filters at multiple scales and orientations\n",
        "\n",
        "        Args:\n",
        "            scales: Number of scales\n",
        "            orientations: Number of orientations\n",
        "\n",
        "        Returns:\n",
        "            List of Gabor filters\n",
        "        \"\"\"\n",
        "        filters = []\n",
        "\n",
        "        # Calculate wavelengths for each scale\n",
        "        wavelengths = [np.pi * (2**i) for i in range(scales)]\n",
        "        sigma_ratio = 0.56  # Empirically determined ratio\n",
        "\n",
        "        for wavelength in wavelengths:\n",
        "            sigma = wavelength * sigma_ratio\n",
        "            size = int(6 * sigma)  # 6 sigma rule\n",
        "\n",
        "            # Generate filters for different orientations\n",
        "            for theta in np.linspace(0, np.pi, orientations, endpoint=False):\n",
        "                kernel = self._create_gabor_kernel(size, sigma, wavelength, theta)\n",
        "                filters.append(kernel)\n",
        "\n",
        "                # Add phase-shifted version (complex part)\n",
        "                kernel_shifted = self._create_gabor_kernel(size, sigma, wavelength,\n",
        "                                                         theta, phase_shift=np.pi/2)\n",
        "                filters.append(kernel_shifted)\n",
        "\n",
        "        return filters\n",
        "\n",
        "    def _create_gabor_kernel(self, size, sigma, wavelength, theta, phase_shift=0):\n",
        "        \"\"\"Helper method to create a single Gabor filter\"\"\"\n",
        "        x = np.linspace(-size//2, size//2, size)\n",
        "        y = np.linspace(-size//2, size//2, size)\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "\n",
        "        # Rotate coordinates\n",
        "        Xr = X*np.cos(theta) + Y*np.sin(theta)\n",
        "        Yr = -X*np.sin(theta) + Y*np.cos(theta)\n",
        "\n",
        "        # Create Gabor filter\n",
        "        gaussian = np.exp(-(Xr**2 + Yr**2)/(2*sigma**2))\n",
        "        sinusoid = np.cos(2*np.pi*Xr/wavelength + phase_shift)\n",
        "        kernel = gaussian * sinusoid\n",
        "\n",
        "        return self.utils.normalize_kernel(kernel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhZSwN8W4zj4"
      },
      "source": [
        "1. Generate Half-disk masks\n",
        "2. Display all the Half-disk masks and save image as HDMasks.png,\n",
        "3. use command \"cv2.imwrite(...)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H43aTHdD4zj4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsO2z2ub4zj5"
      },
      "source": [
        "1. Generate Texton Map\n",
        "2. Filter image using oriented gaussian filter bank\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-jtngqU4zj5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifGTkHv84zj5"
      },
      "source": [
        "1. Generate texture ID's using K-means clustering\n",
        "2. Display texton map and save image as TextonMap_ImageName.png,\n",
        "3. use command \"cv2.imwrite('...)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhd-eznB4zj5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhkWsyiV4zj6"
      },
      "source": [
        "1. Generate Texton Gradient (Tg)\n",
        "2. Perform Chi-square calculation on Texton Map\n",
        "3. Display Tg and save image as Tg_ImageName.png,\n",
        "4. use command \"cv2.imwrite(...)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXPbc8FE4zj6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vrXv0ff4zj6"
      },
      "source": [
        "1. Generate Brightness Map\n",
        "2. Perform brightness binning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_ND-sVC4zj6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKOitvW34zj6"
      },
      "source": [
        "1. Generate Brightness Gradient (Bg)\n",
        "2. Perform Chi-square calculation on Brightness Map\n",
        "3. Display Bg and save image as Bg_ImageName.png,\n",
        "4. use command \"cv2.imwrite(...)\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCOD81PA4zj7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHJXA-HM4zj7"
      },
      "source": [
        "1. Generate Color Map\n",
        "2. Perform color binning or clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m2LGULC4zj7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO27XPii4zj7"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1. Generate Color Gradient (Cg)\n",
        "2. Perform Chi-square calculation on Color Map\n",
        "3. Display Cg and save image as Cg_ImageName.png,\n",
        "4. use command \"cv2.imwrite(...)\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_BnNy7s4zj7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmy__th24zj7"
      },
      "source": [
        "\n",
        "1. Read Sobel Baseline\n",
        "2. use command \"cv2.imread(...)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vapObHsb4zj7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMm0qhf-4zj8"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1. Read Canny Baseline\n",
        "2. use command \"cv2.imread(...)\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZcgUAqK4zj8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1Ut3_c74zj8"
      },
      "source": [
        "\n",
        "\n",
        "1. Combine responses to get pb-lite output\n",
        "2. Display PbLite and save image as PbLite_ImageName.png\n",
        "3. use command \"cv2.imwrite(...)\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpC2Z26r4zj8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2"
      ],
      "metadata": {
        "id": "e2aeH7uq8qR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network Construction"
      ],
      "metadata": {
        "id": "-4iWkcHsItB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "def loss_fn(out, labels):\n",
        "    ###############################################\n",
        "    # Fill your loss function of choice here!\n",
        "    ###############################################\n",
        "    loss = ...\n",
        "    return loss\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = loss_fn(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = loss_fn(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'loss': loss.detach(), 'acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'loss': epoch_loss.item(), 'acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], loss: {:.4f}, acc: {:.4f}\".format(epoch, result['loss'], result['acc']))\n",
        "\n",
        "\n",
        "\n",
        "class CIFAR10Model(ImageClassificationBase):\n",
        "  def __init__(self, InputSize, OutputSize):\n",
        "      \"\"\"\n",
        "      Inputs:\n",
        "      InputSize - Size of the Input\n",
        "      OutputSize - Size of the Output\n",
        "      \"\"\"\n",
        "      #############################\n",
        "      # Fill your network initialization of choice here!\n",
        "      #############################\n",
        "\n",
        "\n",
        "  def forward(self, xb):\n",
        "      \"\"\"\n",
        "      Input:\n",
        "      xb is a MiniBatch of the current image\n",
        "      Outputs:\n",
        "      out - output of the network\n",
        "      \"\"\"\n",
        "      #############################\n",
        "      # Fill your network structure of choice here!\n",
        "      #############################\n",
        "\n",
        "      return out\n",
        ""
      ],
      "metadata": {
        "id": "jGCHa0pfIss-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def tic():\n",
        "    \"\"\"\n",
        "    Function to start timer\n",
        "    Tries to mimic tic() toc() in MATLAB\n",
        "    \"\"\"\n",
        "    StartTime = time.time()\n",
        "    return StartTime\n",
        "\n",
        "def toc(StartTime):\n",
        "    \"\"\"\n",
        "    Function to stop timer\n",
        "    Tries to mimic tic() toc() in MATLAB\n",
        "    \"\"\"\n",
        "    return time.time() - StartTime\n",
        "\n",
        "def FindLatestModel(CheckPointPath):\n",
        "    \"\"\"\n",
        "    Finds Latest Model in CheckPointPath\n",
        "    Inputs:\n",
        "    CheckPointPath - Path where you have stored checkpoints\n",
        "    Outputs:\n",
        "    LatestFile - File Name of the latest checkpoint\n",
        "    \"\"\"\n",
        "    FileList = glob.glob(CheckPointPath + '*.ckpt.index') # * means all if need specific format then *.csv\n",
        "    LatestFile = max(FileList, key=os.path.getctime)\n",
        "    # Strip everything else except needed information\n",
        "    LatestFile = LatestFile.replace(CheckPointPath, '')\n",
        "    LatestFile = LatestFile.replace('.ckpt.index', '')\n",
        "    return LatestFile\n",
        "\n",
        "\n",
        "def convertToOneHot(vector, NumClasses):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    vector - vector of argmax indexes\n",
        "    NumClasses - Number of classes\n",
        "    \"\"\"\n",
        "    return np.equal.outer(vector, np.arange(NumClasses)).astype(np.float)"
      ],
      "metadata": {
        "id": "2SPck2oRdL5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train your neural network"
      ],
      "metadata": {
        "id": "A04kYJ_rJxEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim import AdamW\n",
        "from torchvision.datasets import CIFAR10\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import skimage\n",
        "import PIL\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from skimage import data, exposure, img_as_float\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from torchvision.transforms import ToTensor\n",
        "import argparse\n",
        "import shutil\n",
        "import string\n",
        "from termcolor import colored, cprint\n",
        "import math as m\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def SetupAll(CheckPointPath):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    CheckPointPath - Path to save checkpoints/model\n",
        "    Outputs:\n",
        "    SaveCheckPoint - Save checkpoint every SaveCheckPoint iteration in every epoch, checkpoint saved automatically after every epoch\n",
        "    ImageSize - Size of the image\n",
        "    NumTrainSamples - length(Train)\n",
        "    TrainLabels - Labels corresponding to Train\n",
        "    NumClasses - Number of classes\n",
        "    \"\"\"\n",
        "    # Read and Setup Labels\n",
        "    LabelsPathTrain = '/content/data/TxtFiles/LabelsTrain.txt'\n",
        "    TrainLabels = ReadLabels(LabelsPathTrain)\n",
        "\n",
        "    # If CheckPointPath doesn't exist make the path\n",
        "    if(not (os.path.isdir(CheckPointPath))):\n",
        "       os.makedirs(CheckPointPath)\n",
        "\n",
        "    # Save checkpoint every SaveCheckPoint iteration in every epoch, checkpoint saved automatically after every epoch\n",
        "    SaveCheckPoint = 100\n",
        "\n",
        "    # Image Input Shape\n",
        "    ImageSize = [32, 32, 3]\n",
        "    NumTrainSamples = len(TrainSet)\n",
        "\n",
        "    # Number of classes\n",
        "    NumClasses = 10\n",
        "\n",
        "    return SaveCheckPoint, ImageSize, NumTrainSamples, TrainLabels, NumClasses\n",
        "\n",
        "\n",
        "def ReadLabels(LabelsPathTrain):\n",
        "    if(not (os.path.isfile(LabelsPathTrain))):\n",
        "        print('ERROR: Train Labels do not exist in '+LabelsPathTrain)\n",
        "        sys.exit()\n",
        "    else:\n",
        "        TrainLabels = open(LabelsPathTrain, 'r')\n",
        "        TrainLabels = TrainLabels.read()\n",
        "        TrainLabels = map(float, TrainLabels.split())\n",
        "\n",
        "    return TrainLabels\n",
        "\n",
        "\n",
        "def ReadDirNames(ReadPath):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    ReadPath is the path of the file you want to read\n",
        "    Outputs:\n",
        "    DirNames is the data loaded from /content/data/TxtFiles/DirNames.txt which has full path to all image files without extension\n",
        "    \"\"\"\n",
        "    # Read text files\n",
        "    DirNames = open(ReadPath, 'r')\n",
        "    DirNames = DirNames.read()\n",
        "    DirNames = DirNames.split()\n",
        "    return DirNames\n",
        "\n",
        "\n",
        "def GenerateBatch(TrainSet, TrainLabels, ImageSize, MiniBatchSize):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    TrainSet - Variable with Subfolder paths to train files\n",
        "    NOTE that Train can be replaced by Val/Test for generating batch corresponding to validation (held-out testing in this case)/testing\n",
        "    TrainLabels - Labels corresponding to Train\n",
        "    NOTE that TrainLabels can be replaced by Val/TestLabels for generating batch corresponding to validation (held-out testing in this case)/testing\n",
        "    ImageSize is the Size of the Image\n",
        "    MiniBatchSize is the size of the MiniBatch\n",
        "\n",
        "    Outputs:\n",
        "    I1Batch - Batch of images\n",
        "    LabelBatch - Batch of one-hot encoded labels\n",
        "    \"\"\"\n",
        "    I1Batch = []\n",
        "    LabelBatch = []\n",
        "\n",
        "    ImageNum = 0\n",
        "    while ImageNum < MiniBatchSize:\n",
        "        # Generate random image\n",
        "        RandIdx = random.randint(0, len(TrainSet)-1)\n",
        "\n",
        "        ImageNum += 1\n",
        "\n",
        "    \t  ##########################################################\n",
        "    \t  # Add any standardization or data augmentation here!\n",
        "    \t  ##########################################################\n",
        "\n",
        "        I1, Label = TrainSet[RandIdx]\n",
        "\n",
        "        # Append All Images and Mask\n",
        "        I1Batch.append(I1)\n",
        "        LabelBatch.append(torch.tensor(Label))\n",
        "\n",
        "    return torch.stack(I1Batch), torch.stack(LabelBatch)\n",
        "\n",
        "\n",
        "def PrettyPrint(NumEpochs, DivTrain, MiniBatchSize, NumTrainSamples, LatestFile):\n",
        "    \"\"\"\n",
        "    Prints all stats with all arguments\n",
        "    \"\"\"\n",
        "    print('Number of Epochs Training will run for ' + str(NumEpochs))\n",
        "    print('Factor of reduction in training data is ' + str(DivTrain))\n",
        "    print('Mini Batch Size ' + str(MiniBatchSize))\n",
        "    print('Number of Training Images ' + str(NumTrainSamples))\n",
        "    if LatestFile is not None:\n",
        "        print('Loading latest checkpoint with the name ' + LatestFile)\n",
        "\n",
        "def TrainOperation(TrainLabels, NumTrainSamples, ImageSize,\n",
        "                   NumEpochs, MiniBatchSize, SaveCheckPoint, CheckPointPath,\n",
        "                   DivTrain, LatestFile, TrainSet, LogsPath):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    TrainLabels - Labels corresponding to Train/Test\n",
        "    NumTrainSamples - length(Train)\n",
        "    ImageSize - Size of the image\n",
        "    NumEpochs - Number of passes through the Train data\n",
        "    MiniBatchSize is the size of the MiniBatch\n",
        "    SaveCheckPoint - Save checkpoint every SaveCheckPoint iteration in every epoch, checkpoint saved automatically after every epoch\n",
        "    CheckPointPath - Path to save checkpoints/model\n",
        "    DivTrain - Divide the data by this number for Epoch calculation, use if you have a lot of dataor for debugging code\n",
        "    LatestFile - Latest checkpointfile to continue training\n",
        "    TrainSet - The training dataset\n",
        "    LogsPath - Path to save Tensorboard Logs\n",
        "    Outputs:\n",
        "    Saves Trained network in CheckPointPath and Logs to LogsPath\n",
        "    \"\"\"\n",
        "    # Initialize the model\n",
        "    model = CIFAR10Model(InputSize=3*32*32,OutputSize=10)\n",
        "    ###############################################\n",
        "    # Fill your optimizer of choice here!\n",
        "    ###############################################\n",
        "    Optimizer = ...\n",
        "\n",
        "    # Tensorboard\n",
        "    # Create a summary to monitor loss tensor\n",
        "    Writer = SummaryWriter(LogsPath)\n",
        "\n",
        "    if LatestFile is not None:\n",
        "        CheckPoint = torch.load(CheckPointPath + LatestFile + '.ckpt')\n",
        "        # Extract only numbers from the name\n",
        "        StartEpoch = int(''.join(c for c in LatestFile.split('a')[0] if c.isdigit()))\n",
        "        model.load_state_dict(CheckPoint['model_state_dict'])\n",
        "        print('Loaded latest checkpoint with the name ' + LatestFile + '....')\n",
        "    else:\n",
        "        StartEpoch = 0\n",
        "        print('New model initialized....')\n",
        "\n",
        "    for Epochs in tqdm(range(StartEpoch, NumEpochs)):\n",
        "        NumIterationsPerEpoch = int(NumTrainSamples/MiniBatchSize/DivTrain)\n",
        "        for PerEpochCounter in tqdm(range(NumIterationsPerEpoch)):\n",
        "            Batch = GenerateBatch(TrainSet, TrainLabels, ImageSize, MiniBatchSize)\n",
        "\n",
        "            # Predict output with forward pass\n",
        "            LossThisBatch = model.training_step(Batch)\n",
        "\n",
        "            Optimizer.zero_grad()\n",
        "            LossThisBatch.backward()\n",
        "            Optimizer.step()\n",
        "\n",
        "            # Save checkpoint every some SaveCheckPoint's iterations\n",
        "            if PerEpochCounter % SaveCheckPoint == 0:\n",
        "                # Save the Model learnt in this epoch\n",
        "                SaveName =  CheckPointPath + str(Epochs) + 'a' + str(PerEpochCounter) + 'model.ckpt'\n",
        "\n",
        "                torch.save({'epoch': Epochs,'model_state_dict': model.state_dict(),'optimizer_state_dict': Optimizer.state_dict(),'loss': LossThisBatch}, SaveName)\n",
        "                print('\\n' + SaveName + ' Model Saved...')\n",
        "\n",
        "            result = model.validation_step(Batch)\n",
        "            model.epoch_end(Epochs*NumIterationsPerEpoch + PerEpochCounter, result)\n",
        "            # Tensorboard\n",
        "            Writer.add_scalar('LossEveryIter', result[\"loss\"], Epochs*NumIterationsPerEpoch + PerEpochCounter)\n",
        "            Writer.add_scalar('Accuracy', result[\"acc\"], Epochs*NumIterationsPerEpoch + PerEpochCounter)\n",
        "            # If you don't flush the tensorboard doesn't update until a lot of iterations!\n",
        "            Writer.flush()\n",
        "\n",
        "        # Save model every epoch\n",
        "        SaveName = CheckPointPath + str(Epochs) + 'model.ckpt'\n",
        "        torch.save({'epoch': Epochs,'model_state_dict': model.state_dict(),'optimizer_state_dict': Optimizer.state_dict(),'loss': LossThisBatch}, SaveName)\n",
        "        print('\\n' + SaveName + ' Model Saved...')\n",
        "\n",
        "\n",
        "\n",
        "# Default Hyperparameters\n",
        "NumEpochs = 50\n",
        "TrainSet = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=ToTensor())\n",
        "DivTrain = 1.0\n",
        "MiniBatchSize = 1\n",
        "LoadCheckPoint = 0\n",
        "CheckPointPath = \"/content/Checkpoints/\"\n",
        "LogsPath = \"/content/Logs\"\n",
        "\n",
        "# Setup all needed parameters including file reading\n",
        "SaveCheckPoint, ImageSize, NumTrainSamples, TrainLabels, NumClasses = SetupAll(CheckPointPath)\n",
        "\n",
        "# Find Latest Checkpoint File\n",
        "if LoadCheckPoint==1:\n",
        "    LatestFile = FindLatestModel(CheckPointPath)\n",
        "else:\n",
        "    LatestFile = None\n",
        "\n",
        "# Pretty print stats\n",
        "PrettyPrint(NumEpochs, DivTrain, MiniBatchSize, NumTrainSamples, LatestFile)\n",
        "\n",
        "TrainOperation(TrainLabels, NumTrainSamples, ImageSize,\n",
        "                NumEpochs, MiniBatchSize, SaveCheckPoint, CheckPointPath,\n",
        "                DivTrain, LatestFile, TrainSet, LogsPath)"
      ],
      "metadata": {
        "id": "hcGOFRE2JueB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test your neural network"
      ],
      "metadata": {
        "id": "HKVVLygOJ1kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "from skimage import data, exposure, img_as_float\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from torchvision.transforms import ToTensor\n",
        "import argparse\n",
        "import shutil\n",
        "import string\n",
        "import math as m\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "\n",
        "def SetupAll():\n",
        "    \"\"\"\n",
        "    Outputs:\n",
        "    ImageSize - Size of the Image\n",
        "    \"\"\"\n",
        "    # Image Input Shape\n",
        "    ImageSize = [32, 32, 3]\n",
        "\n",
        "    return ImageSize\n",
        "\n",
        "def StandardizeInputs(Img):\n",
        "    ##########################################################################\n",
        "    # Add any standardization or cropping/resizing if used in Training here!\n",
        "    ##########################################################################\n",
        "    return Img\n",
        "\n",
        "def ReadImages(Img):\n",
        "    \"\"\"\n",
        "    Outputs:\n",
        "    I1Combined - I1 image after any standardization and/or cropping/resizing to ImageSize\n",
        "    I1 - Original I1 image for visualization purposes only\n",
        "    \"\"\"\n",
        "    I1 = Img\n",
        "\n",
        "    if(I1 is None):\n",
        "        # OpenCV returns empty list if image is not read!\n",
        "        print('ERROR: Image I1 cannot be read')\n",
        "        sys.exit()\n",
        "\n",
        "    I1S = StandardizeInputs(np.float32(I1))\n",
        "\n",
        "    I1Combined = np.expand_dims(I1S, axis=0)\n",
        "\n",
        "    return I1Combined, I1\n",
        "\n",
        "\n",
        "def TestOperation(ImageSize, ModelPath, TestSet, LabelsPathPred):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    ImageSize is the size of the image\n",
        "    ModelPath - Path to load trained model from\n",
        "    TestSet - The test dataset\n",
        "    LabelsPathPred - Path to save predictions\n",
        "    Outputs:\n",
        "    Predictions written to /content/data/TxtFiles/PredOut.txt\n",
        "    \"\"\"\n",
        "    # Predict output with forward pass, MiniBatchSize for Test is 1\n",
        "    model = CIFAR10Model(InputSize=3*32*32,OutputSize=10)\n",
        "\n",
        "    CheckPoint = torch.load(ModelPath)\n",
        "    model.load_state_dict(CheckPoint['model_state_dict'])\n",
        "    print('Number of parameters in this model are %d ' % len(model.state_dict().items()))\n",
        "\n",
        "    OutSaveT = open(LabelsPathPred, 'w')\n",
        "\n",
        "    for count in tqdm(range(len(TestSet))):\n",
        "        Img, Label = TestSet[count]\n",
        "        Img, ImgOrg = ReadImages(Img)\n",
        "        PredT = torch.argmax(model(Img)).item()\n",
        "\n",
        "        OutSaveT.write(str(PredT)+'\\n')\n",
        "    OutSaveT.close()\n",
        "\n",
        "def Accuracy(Pred, GT):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    Pred are the predicted labels\n",
        "    GT are the ground truth labels\n",
        "    Outputs:\n",
        "    Accuracy in percentage\n",
        "    \"\"\"\n",
        "    return (np.sum(np.array(Pred)==np.array(GT))*100.0/len(Pred))\n",
        "\n",
        "def ReadLabels(LabelsPathTest, LabelsPathPred):\n",
        "    if(not (os.path.isfile(LabelsPathTest))):\n",
        "        print('ERROR: Test Labels do not exist in '+LabelsPathTest)\n",
        "        sys.exit()\n",
        "    else:\n",
        "        LabelTest = open(LabelsPathTest, 'r')\n",
        "        LabelTest = LabelTest.read()\n",
        "        LabelTest = map(float, LabelTest.split())\n",
        "\n",
        "    if(not (os.path.isfile(LabelsPathPred))):\n",
        "        print('ERROR: Pred Labels do not exist in '+LabelsPathPred)\n",
        "        sys.exit()\n",
        "    else:\n",
        "        LabelPred = open(LabelsPathPred, 'r')\n",
        "        LabelPred = LabelPred.read()\n",
        "        LabelPred = map(float, LabelPred.split())\n",
        "\n",
        "    return LabelTest, LabelPred\n",
        "\n",
        "def ConfusionMatrix(LabelsTrue, LabelsPred):\n",
        "    \"\"\"\n",
        "    LabelsTrue - True labels\n",
        "    LabelsPred - Predicted labels\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the confusion matrix using sklearn.\n",
        "    LabelsTrue, LabelsPred = list(LabelsTrue), list(LabelsPred)\n",
        "    cm = confusion_matrix(y_true=LabelsTrue,  # True class for test-set.\n",
        "                          y_pred=LabelsPred)  # Predicted class.\n",
        "\n",
        "    # Print the confusion matrix as text.\n",
        "    for i in range(10):\n",
        "        print(str(cm[i, :]) + ' ({0})'.format(i))\n",
        "\n",
        "    # Print the class-numbers for easy reference.\n",
        "    class_numbers = [\" ({0})\".format(i) for i in range(10)]\n",
        "    print(\"\".join(class_numbers))\n",
        "\n",
        "    print('Accuracy: '+ str(Accuracy(LabelsPred, LabelsTrue)), '%')\n",
        "\n",
        "\n",
        "ModelPath = \"/content/Checkpoints/0a100model.ckpt\"\n",
        "LabelsPath = \"/content/data/TxtFiles/LabelsTest.txt\"\n",
        "TestSet = CIFAR10(root='data/', train=False)\n",
        "\n",
        "\n",
        "# Setup all needed parameters including file reading\n",
        "ImageSize = SetupAll()\n",
        "\n",
        "# Define PlaceHolder variables for Input and Predicted output\n",
        "LabelsPathPred = '/content/data/TxtFiles/PredOut.txt' # Path to save predicted labels\n",
        "\n",
        "TestOperation(ImageSize, ModelPath, TestSet, LabelsPathPred)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "LabelsTrue, LabelsPred = ReadLabels(LabelsPath, LabelsPathPred)\n",
        "ConfusionMatrix(LabelsTrue, LabelsPred)"
      ],
      "metadata": {
        "id": "lY-9nSVBJ282"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2762af0fb94193cc770e2dbb99b50503f4c838317f9fa63bb8a7461c3d6fd280"
      }
    },
    "colab": {
      "name": "hw0_to_be_filled.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}